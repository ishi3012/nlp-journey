# **NLP Journey** ðŸš€

Welcome to my **NLP Journey**! This repository showcases the projects, assignments, and explorations I have undertaken as part of my NLP Class. Here, you'll find various applications of **Natural Language Processing (NLP)**, from fundamental concepts to more advanced projects.

## **Table of Contents**

1. [About](#about)
2. [Assignments](#assignments)
3. [Projects](#projects)
4. [Technologies Used](#technologies-used)
5. [How to Use This Repo](#how-to-use-this-repo)
6. [License](#license)

---

## **About**

This repository serves as a collection of all my work related to NLP, including class assignments and personal projects. The focus is on exploring different aspects of **Natural Language Processing** using state-of-the-art methods and tools such as **deep learning**, **transformers**, and **traditional NLP techniques**.

The primary goals of this repository are to:
- Develop and showcase hands-on projects in NLP.
- Apply NLP techniques to real-world datasets.
- Explore advanced topics like **transformers**, **BERT**, **GPT**, **Named Entity Recognition (NER)**, and **Sentiment Analysis**.
- Use various Python libraries and tools such as **TensorFlow**, **PyTorch**, **spaCy**, and **Hugging Face Transformers**.

---

## **Assignments**

Here you'll find the assignments I completed as part of my **NLP class**. Each folder contains a detailed description, code notebooks, and results.

| Assignment | Topic | Description |
|------------|-------|-------------|
| [Assignment 1](./assignments/assignment1) | Text Preprocessing | An introduction to text preprocessing techniques, including tokenization, stemming, lemmatization, and stopword removal. |
| [Assignment 2](./assignments/assignment2) | Word Embeddings | Understanding and implementing Word2Vec and GloVe for generating word embeddings. |

---

## **Projects**

This section contains larger, self-driven projects that explore more complex NLP problems. These projects aim to apply NLP concepts to real-world scenarios.

| Project | Topic | Description |
|---------|-------|-------------|
| [Sentiment Analyzer](./projects/project1-nlp-app) | Sentiment Analysis | A sentiment analysis tool that classifies text into positive, negative, or neutral sentiments using **BERT** and **LSTM** models. |
| [NER for Healthcare Data](./projects/project2-ner) | Named Entity Recognition | A custom NER model for extracting entities such as drug names, diseases, and symptoms from healthcare texts using **spaCy** and **Transformer models**. |
| [Text Summarization](./projects/project3-summarization) | Text Summarization | An automatic text summarizer using **GPT models** to condense lengthy documents into short, coherent summaries. |
| [Language Translation](./projects/project4-translation) | Machine Translation | A translation system built using **seq2seq** models for translating between English and French. |

---

## **Technologies Used**

The repository leverages various tools and technologies commonly used in NLP:

- **Languages**: Python
- **Libraries**: 
  - **NLP**: NLTK, spaCy, Hugging Face Transformers, Gensim
  - **Machine Learning**: TensorFlow, PyTorch, Scikit-learn
  - **Data Manipulation**: Pandas, NumPy
  - **Visualization**: Matplotlib, Seaborn
- **Notebooks**: Jupyter, Google Colab
- **Version Control**: Git & GitHub
---

## **How to Use This Repo**

1. **Clone this repository:**
   ```bash
   git clone https://github.com/ishi3012/nlp-journey
2. **Navigate to a specific assignment or project: Each folder has a detailed README.md explaining the steps and requirements to run the code.**
   ```bash
   cd assignments/assignment1
3. **Install dependencies: You can find required dependencies in the requirements.txt file. To install them:**
   ```bash
   pip install -r requirements.txt
4. **Run the Jupyter notebooks: Open the Jupyter notebook and follow the code blocks. Use the provided data links or prepare your datasets as per the instructions.**

## **License**
This repository is licensed under the MIT License. See the [LICENSE](./LICENSE) file for more details.

## **Contact**
Feel free to reach out if you have any questions or suggestions!
- [Email](ishishiv3012@gmail.com)